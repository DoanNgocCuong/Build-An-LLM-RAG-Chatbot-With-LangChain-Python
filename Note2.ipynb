{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. How Run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cài database local Milvus bằng Docker - https://milvus.io/docs/install_milvus_docker.md\n",
    "```bash\n",
    "docker-compose up --build\n",
    "docker run -p 3000:3000 -e MILVUS_URL=localhost:19530 zilliz/attu:v2.4\n",
    "```\n",
    "2. Ctrl Shift P -> cài .venv\n",
    "- Cài requirements.txt\n",
    "```markdown\n",
    "HÃY CHO TÔI BIẾT\n",
    "1. các lỗi gì đã xảy ra\n",
    "2. Tại sao xảy ra\n",
    "3. Bạn đã fix  như nào ???\n",
    "```\n",
    "\n",
    "4. `.env`\n",
    "```bash\n",
    "OPENAI_API_KEY=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\n",
    "\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_API_KEY=\"your-langchain-api-key-here\"\n",
    "LANGCHAIN_PROJECT=\"project-name\"\n",
    "```\n",
    "\n",
    "3. Chạy ứng dụng: \n",
    "\n",
    "- Crawl data về local trước khi bắt đầu chạy ứng dụng. Mở Terminal/Command Prompt, di chuyển vào thư mục src và chạy:\n",
    "```python\n",
    "cd src\n",
    "python crawl.py\n",
    "```\n",
    "\n",
    "- Chạy ứng dụng:\n",
    "```python\n",
    "streamlit run main.py\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 lỗi cài thư viện"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tôi sẽ phân tích chi tiết các vấn đề:\n",
    "\n",
    "### 1. Các lỗi đã xảy ra:\n",
    "- **Lỗi 1**: Conflict giữa `pydantic` và `chromadb`\n",
    "- **Lỗi 2**: Không thể build wheel cho `chroma-hnswlib` vì thiếu Microsoft Visual C++ Build Tools\n",
    "\n",
    "### 2. Nguyên nhân:\n",
    "- **Lỗi 1**: `chromadb` phiên bản cũ yêu cầu `pydantic<2.0` trong khi file requirements.txt yêu cầu `pydantic>=2.0.0`\n",
    "- **Lỗi 2**: `chromadb` cần phải được biên dịch từ source code trên Windows, điều này yêu cầu C++ compiler\n",
    "\n",
    "### 3. Cách fix:\n",
    "Tôi đã đề xuất thay đổi sang sử dụng FAISS thay vì Chroma vì:\n",
    "1. FAISS có sẵn pre-built wheels cho Windows\n",
    "2. Không cần C++ compiler\n",
    "3. Hiệu năng tốt và được sử dụng rộng rãi\n",
    "\n",
    "Các thay đổi cụ thể trong requirements.txt:\n",
    "```requirements.txt\n",
    "# Thay đổi trong phần LangChain & AI\n",
    "- langchain-chroma>=0.0.1\n",
    "+ langchain-faiss>=0.0.1\n",
    "\n",
    "# Thay đổi trong phần Vector Database & Search\n",
    "- chromadb>=0.4.0\n",
    "+ faiss-cpu>=1.7.4\n",
    "```\n",
    "\n",
    "Đây là giải pháp đơn giản nhất vì:\n",
    "1. Tránh phải cài đặt Visual Studio Build Tools\n",
    "2. Không cần xử lý conflicts về dependencies\n",
    "3. FAISS là một lựa chọn tốt cho vector store, được sử dụng rộng rãi trong production\n",
    "\n",
    "Nếu bạn vẫn muốn sử dụng Chroma, bạn sẽ cần:\n",
    "1. Cài đặt Microsoft Visual C++ Build Tools\n",
    "2. Đảm bảo version compatibility giữa pydantic và chromadb\n",
    "3. Rebuild lại virtual environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Tìm hiểu về crawl data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Tôi thấy bạn đang cố chạy file `crawl_data.py` nhưng file thực tế là `crawl.py`. Đây là cách để chạy đúng quy trình:\n",
    "\n",
    "1. **Đầu tiên, chạy crawl.py để lấy dữ liệu**:\n",
    "```bash\n",
    "python crawl.py\n",
    "```\n",
    "\n",
    "File này sẽ:\n",
    "- Crawl dữ liệu từ `https://www.stack-ai.com/docs`\n",
    "- Lưu vào `data/stack.json`\n",
    "- Tham khảo hàm `main()` trong `crawl.py`:\n",
    "\n",
    "```81:92:src/crawl.py\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính điều khiển luồng chương trình:\n",
    "    1. Crawl dữ liệu từ trang web stack-ai\n",
    "    2. Lưu dữ liệu đã crawl vào file JSON\n",
    "    3. In kết quả crawl để kiểm tra\n",
    "    \"\"\"\n",
    "    # Crawl dữ liệu từ trang docs của stack-ai\n",
    "    data = crawl_web('https://www.stack-ai.com/docs')\n",
    "    # Lưu dữ liệu vào thư mục data_v2\n",
    "    save_data_locally(data, 'stack.json', 'data')\n",
    "    print('data: ', data)  # In dữ liệu đã crawl\n",
    "```\n",
    "\n",
    "\n",
    "2. **Sau khi có dữ liệu, chạy seed_data.py để đưa vào Milvus**:\n",
    "```bash\n",
    "python seed_data.py\n",
    "```\n",
    "\n",
    "File này sẽ:\n",
    "- Đọc dữ liệu từ `data/stack.json`\n",
    "- Tạo embeddings và lưu vào Milvus\n",
    "- Tham khảo hàm `main()` trong `seed_data.py`:\n",
    "\n",
    "```150:167:src/seed_data.py\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Hàm chính để kiểm thử các chức năng của module\n",
    "    Thực hiện:\n",
    "        1. Test seed_milvus với dữ liệu từ file local 'stack.json'\n",
    "        2. (Đã comment) Test seed_milvus_live với dữ liệu từ trang web stack-ai\n",
    "    Chú ý:\n",
    "        - Đảm bảo Milvus server đang chạy tại localhost:19530\n",
    "        - Các biến môi trường cần thiết (như OPENAI_API_KEY) đã được cấu hình\n",
    "    \"\"\"\n",
    "    # Test seed_milvus với dữ liệu local\n",
    "    seed_milvus('http://localhost:19530', 'data_test', 'stack.json', 'data', use_ollama=False)\n",
    "    # Test seed_milvus_live với URL trực tiếp\n",
    "    # seed_milvus_live('https://www.stack-ai.com/docs', 'http://localhost:19530', 'data_test_live', 'stack-ai', use_ollama=False)\n",
    "# Chạy main() nếu file được thực thi trực tiếp\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```\n",
    "\n",
    "\n",
    "3. **Cuối cùng mới chạy ứng dụng Streamlit**:\n",
    "```bash\n",
    "streamlit run main.py\n",
    "```\n",
    "\n",
    "Lỗi \"Không tìm thấy documents trong collection 'data_test'\" xảy ra vì bạn chưa thực hiện bước 1 và 2 để tạo dữ liệu trước khi chạy ứng dụng.\n",
    "\n",
    "Tóm lại quy trình đầy đủ là:\n",
    "1. Crawl dữ liệu (`crawl.py`)\n",
    "2. Seed dữ liệu vào Milvus (`seed_data.py`)\n",
    "3. Chạy ứng dụng (`main.py) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Langchain \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run any LLM, Chat model, or Chain. Its trace will be sent to this project.\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
